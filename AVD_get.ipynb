{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AVD_get",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seungbobkimpants/reilly_nlp/blob/master/AVD_get.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhAyZ6ouyxck",
        "colab_type": "text"
      },
      "source": [
        "# **Getting text arousal, valence, and dominance using Warriner, Kuperman & Brysbaert (2013)**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCqwFX-mf-aN",
        "colab_type": "text"
      },
      "source": [
        "## **Preliminaries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0eN_6IZ33RE",
        "colab_type": "text"
      },
      "source": [
        "We are going to import some useful libraries first.\n",
        "\n",
        "* `numpy` supports fast computation on large, n-dimensional arrays. Python is slower than languages like C and Java, so `numpy` tries to speed it up. It's conventional to import it as `np`.\n",
        "* `pandas` is built on top of `numpy`. It gives you some easy tools to visualize and analyze tabular (2-dimensional) data. It's conventional to import it as `pd`.\n",
        "* `spacy` is a fast and fancy natural language processing library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YkjYe2gyqqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfwvG3z96cHS",
        "colab_type": "text"
      },
      "source": [
        "Though spaCy and NLTK both come with their own lemmatizers, they are not that good. Brad Jascob's LemmInflect is better! So we'll use it. `https://github.com/bjascob/LemmInflect`\n",
        "\n",
        "You can run bash commands after the `!` symbol. Because Colab doesn't come with LemmInflect, I have to install it with `pip`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdg7mshvpIZj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5f42f942-2846-4195-ee52-c483d777cb6d"
      },
      "source": [
        "!pip3 install lemminflect\n",
        "import lemminflect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lemminflect in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lemminflect) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzbTkdKCgG3I",
        "colab_type": "text"
      },
      "source": [
        "## **Dealing with data**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJDVJgHZlqZN",
        "colab_type": "text"
      },
      "source": [
        "~~First, obtain WKB's measures at `http://crr.ugent.be/archives/1003` then upload here by connecting to the runtime, then uploading `Ratings_Warriner_et_al.csv` in the Files sidebar.~~\n",
        "\n",
        "OK, because it's annoying to upload the WKB ratings every time, we are going to keep it in the `Summer Cog Zoom May 20` folder on Google Drive. We can mount Google Drive by running the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBtnYk213VBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b2ec8731-22ee-4e0c-b1ed-9ca87def5862"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0WmogGFfNnz",
        "colab_type": "text"
      },
      "source": [
        "Read in the lexicon, and call in only the relevant columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cz5rzzi-0cEr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "add3cf25-858d-4f6b-beb7-ad291d04a6fd"
      },
      "source": [
        "ratings_path = '/content/drive/My Drive/Summer Cog Zoom May 20/Linguistic/Ratings_Warriner_et_al.csv'\n",
        "\n",
        "# df meaning dataframe\n",
        "df = pd.read_csv(ratings_path, usecols=['Word', 'V.Mean.Sum', 'A.Mean.Sum', 'D.Mean.Sum'])\n",
        "print('There are this many words:', len(df)-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are this many words: 13914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dOH9g_ie3rV",
        "colab_type": "text"
      },
      "source": [
        "Obviously, there are more than 13914 words in the English language. We will have to ignore all the words not in this list, but if we have time, we could try to extrapolate ('bootstrap') using word vector distances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCpd577rglPJ",
        "colab_type": "text"
      },
      "source": [
        "Let's define some test text. We'll modify this part to use actual text data later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kQukh-BfI0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_text = 'GRASSLEY: As part of judge Kavanaugh’s nomination to the Supreme Court, the FBI conducted its sixth full field background investigation of Judge Kavanaugh since 1993, 25 years ago. Nowhere in any of these six FBI reports, which committee investigators have reviewed on a bipartisan basis, was there a whiff of any issue — any issue at all related in any way to inappropriate sexual behavior. \\n Dr. Ford first raised her allegations in a secret letter to the ranking member nearly two months ago in July. This letter was secret from July 30th, September 13th to — no, July 30th until September 13th when I first heard about it.'\n",
        "\n",
        "evil_text = 'I fucking hate that stupid asshole! I am so angry!'\n",
        "good_text = 'I really love that beautiful angel. I am feeling blessed.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgNvzd5agz7L",
        "colab_type": "text"
      },
      "source": [
        "## **The fun stuff**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQ-7yXzyg7bH",
        "colab_type": "text"
      },
      "source": [
        "We'll first load in one of spaCy's pre-trained English models. It's customary to call it `nlp`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LApNI3SDhJO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load spaCy's pre-trained English model and call it nlp\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "# try large"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcUc0RNRhLKf",
        "colab_type": "text"
      },
      "source": [
        "Feeding a text into spaCy's models automatically does some NLP for you. So, once we feed `test_text` into `nlp`, and call it `doc`, we can ask what the sentences are in `test_text`, for example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U4XyTBVhxGq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "e9f5d26f-8805-4043-c1b8-8c4e062696eb"
      },
      "source": [
        "doc = nlp(test_text)\n",
        "\n",
        "sentences = list(doc.sents)\n",
        "print('The sentences are:')\n",
        "for s in sentences:\n",
        "  print(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentences are:\n",
            "GRASSLEY:\n",
            "As part of judge Kavanaugh’s nomination to the Supreme Court, the FBI conducted its sixth full field background investigation of Judge Kavanaugh since 1993, 25 years ago.\n",
            "Nowhere in any of these six FBI reports, which committee investigators have reviewed on a bipartisan basis, was there a whiff of any issue — any issue at all related in any way to inappropriate sexual behavior. \n",
            " \n",
            "Dr. Ford first raised her allegations in a secret letter to the ranking member nearly two months ago in July.\n",
            "This letter was secret from July 30th, September 13th to — no, July 30th until September 13th when I first heard about it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CScCficYh-ku",
        "colab_type": "text"
      },
      "source": [
        "But we don't really care about sentence chunking for getting AVD values. Instead, we will need all the tokens, which are the default iterable units in a `doc`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nho-hPFTieyC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0524cefd-5577-4d37-a454-fd817374f168"
      },
      "source": [
        "lemmata = [token.lemma_ for token in doc]\n",
        "print('Lemmata:', lemmata)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemmata: ['GRASSLEY', ':', 'as', 'part', 'of', 'judge', 'Kavanaugh', '’s', 'nomination', 'to', 'the', 'Supreme', 'Court', ',', 'the', 'FBI', 'conduct', '-PRON-', 'sixth', 'full', 'field', 'background', 'investigation', 'of', 'Judge', 'Kavanaugh', 'since', '1993', ',', '25', 'year', 'ago', '.', 'nowhere', 'in', 'any', 'of', 'these', 'six', 'FBI', 'report', ',', 'which', 'committee', 'investigator', 'have', 'review', 'on', 'a', 'bipartisan', 'basis', ',', 'be', 'there', 'a', 'whiff', 'of', 'any', 'issue', '—', 'any', 'issue', 'at', 'all', 'relate', 'in', 'any', 'way', 'to', 'inappropriate', 'sexual', 'behavior', '.', '\\n ', 'Dr.', 'Ford', 'first', 'raise', '-PRON-', 'allegation', 'in', 'a', 'secret', 'letter', 'to', 'the', 'rank', 'member', 'nearly', 'two', 'month', 'ago', 'in', 'July', '.', 'this', 'letter', 'be', 'secret', 'from', 'July', '30th', ',', 'September', '13th', 'to', '—', 'no', ',', 'July', '30th', 'until', 'September', '13th', 'when', '-PRON-', 'first', 'hear', 'about', '-PRON-', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8ZJXcVcilmB",
        "colab_type": "text"
      },
      "source": [
        "The strange one-line code above uses *list comprehension*. Instead of writing a 3+ line for loop, we can stick it into one loop. More concretely, \n",
        "\n",
        "`lemmata = [token.lemma_ for token in doc]` \n",
        "\n",
        "is equivalent to \n",
        "\n",
        "```\n",
        "lemmata = []\n",
        "for token in doc:\n",
        "  lemmata.append(token.lemma_)\n",
        "```\n",
        "And we can even use conditionals with it:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiUtX8-Ljdfy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ccce3a55-2e4b-43a2-9d6d-be6c5e24f508"
      },
      "source": [
        "present = [lem for lem in lemmata if (df['Word']==lem).any()]\n",
        "print('Lemmata in WKB:', present)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemmata in WKB: ['part', 'judge', 'nomination', 'conduct', 'full', 'field', 'background', 'investigation', 'year', 'six', 'report', 'committee', 'investigator', 'have', 'review', 'basis', 'be', 'whiff', 'issue', 'issue', 'relate', 'way', 'inappropriate', 'sexual', 'behavior', 'first', 'raise', 'allegation', 'secret', 'letter', 'rank', 'member', 'two', 'month', 'letter', 'be', 'secret', 'first', 'hear']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sS3juu7WkGai",
        "colab_type": "text"
      },
      "source": [
        "Just to be clear, `(df['Word']==lem).any()` checks whether there is any word in the `Word` column in `df` that matches the lemma, then returns a boolean (true/false) value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU15Eb6gkne6",
        "colab_type": "text"
      },
      "source": [
        "We can write a quick function/method to return the vertical index of a word (basically copy-pasted from StackOverflow):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MwJfmL9k023",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def idx(element):\n",
        "  return (df[df['Word']==element].index)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRy_53brk26S",
        "colab_type": "text"
      },
      "source": [
        "Then using the `at[index, column_name]` method that comes with `pandas`, we can find the arousal/valence/dominance values for a word in their respective columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YiQAggYgTKP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "8a93c6fc-cae7-4b42-dd65-f1b87d42eff9"
      },
      "source": [
        "arousal_values = [df.at[idx(lem), 'A.Mean.Sum'] for lem in present]\n",
        "valence_values = [df.at[idx(lem), 'V.Mean.Sum'] for lem in present]\n",
        "dominance_values = [df.at[idx(lem), 'D.Mean.Sum'] for lem in present]\n",
        "\n",
        "print('Mean arousal:', sum(arousal_values)/len(arousal_values))\n",
        "print('Mean valence:', sum(valence_values)/len(valence_values))\n",
        "print('Mean dominance:', sum(dominance_values)/len(dominance_values))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean arousal: 4.026923076923078\n",
            "Mean valence: 5.451538461538464\n",
            "Mean dominance: 5.579487179487179\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0s0VUOKlQXE",
        "colab_type": "text"
      },
      "source": [
        "Here are the results for the test texts we defined earlier:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fMlWkzVeqI1",
        "colab_type": "text"
      },
      "source": [
        "Good text:\n",
        "* Mean arousal: 4.471666666666667\n",
        "* Mean valence: 6.859999999999999\n",
        "* Mean dominance: 5.891666666666667\n",
        "\n",
        "Evil text: \n",
        "* Mean arousal: 5.578333333333333\n",
        "* Mean valence: 3.4516666666666667\n",
        "* Mean dominance: 4.323333333333333\n",
        "\n",
        "Kavanope:\n",
        "* Mean arousal: 4.026923076923078 \n",
        "* Mean valence: 5.451538461538464\n",
        "* Mean dominance: 5.579487179487179\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptkirx3jskFX",
        "colab_type": "text"
      },
      "source": [
        "## **Automating the process**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdH53tFjzKkM",
        "colab_type": "text"
      },
      "source": [
        "Let's write a function to do all this in one line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj7OobcKzJWo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def avd_get(text):\n",
        "  doc = nlp(text)\n",
        "  lemmata = [token.lemma_ for token in doc]\n",
        "  present = [lem for lem in lemmata if (df['Word']==lem).any()]\n",
        "  arousal_values = [df.at[idx(lem), 'A.Mean.Sum'] for lem in present]\n",
        "  valence_values = [df.at[idx(lem), 'V.Mean.Sum'] for lem in present]\n",
        "  dominance_values = [df.at[idx(lem), 'D.Mean.Sum'] for lem in present]\n",
        "\n",
        "  return sum(arousal_values)/len(arousal_values), sum(valence_values)/len(valence_values), sum(dominance_values)/len(dominance_values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuXtZzrjtFy9",
        "colab_type": "text"
      },
      "source": [
        "Try it out:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1dkXYGQ0lQT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d18159c-7ec3-48c0-8d50-aff28e4f64fb"
      },
      "source": [
        "avd_get(test_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4.026923076923078, 5.451538461538464, 5.579487179487179)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weDyIbM5tHRy",
        "colab_type": "text"
      },
      "source": [
        "Beautiful. Now, we want to be able to take a folder containing all the files, and then write all these values into a CSV. Because it's a hassle to upload all the input files every time, we are going to access the input files from Google Drive. \n",
        "\n",
        "Once we have read in all the files from `input_data`, we store a list of `(filename, contents)` tuples as `documents`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FtCjoLhtanF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "input_path = '/content/drive/My Drive/Summer Cog Zoom May 20/Linguistic/input_data'\n",
        "\n",
        "documents = os.listdir(input_path)\n",
        "\n",
        "documents = [(name, open(input_path+'/'+name, 'r').read()) for name in documents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj0en3z85wqQ",
        "colab_type": "text"
      },
      "source": [
        "Then we can get to work writing the AVD values into a CSV. NB this can feel quite slow because for each text spaCy has to apply `nlp()` to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpIqt4Xwv89t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "output_path = '/content/drive/My Drive/Summer Cog Zoom May 20/Linguistic/avd_output.csv'\n",
        "with open(output_path, 'w') as file:\n",
        "    writer = csv.writer(file, delimiter=',')\n",
        "    writer.writerow(['name','arousal','valence','dominance'])\n",
        "    for d in documents:\n",
        "      name, text = d\n",
        "      arousal, valence, dominance = avd_get(text)\n",
        "      writer.writerow([name, arousal, valence, dominance])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKfHx7BI6Wwn",
        "colab_type": "text"
      },
      "source": [
        "Finally, let's take a look at the resulting CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwJZ7Lij6ZUp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "ebbdd086-db38-4fbe-9b17-9e11fd31b5fa"
      },
      "source": [
        "output_df = pd.read_csv(output_path)\n",
        "display(output_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>arousal</th>\n",
              "      <th>valence</th>\n",
              "      <th>dominance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Copy of P01_T04_edited.txt</td>\n",
              "      <td>4.022658</td>\n",
              "      <td>5.993507</td>\n",
              "      <td>5.739699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Copy of P03_T04.json.txt</td>\n",
              "      <td>3.964554</td>\n",
              "      <td>6.215812</td>\n",
              "      <td>5.796568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Copy of P02_T04_speakerID.txt</td>\n",
              "      <td>3.918740</td>\n",
              "      <td>5.875603</td>\n",
              "      <td>5.669517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Copy of P04_T04.json.txt</td>\n",
              "      <td>4.019333</td>\n",
              "      <td>5.977841</td>\n",
              "      <td>5.651619</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            name   arousal   valence  dominance\n",
              "0     Copy of P01_T04_edited.txt  4.022658  5.993507   5.739699\n",
              "1       Copy of P03_T04.json.txt  3.964554  6.215812   5.796568\n",
              "2  Copy of P02_T04_speakerID.txt  3.918740  5.875603   5.669517\n",
              "3       Copy of P04_T04.json.txt  4.019333  5.977841   5.651619"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}